# main.py
import streamlit as st
import pandas as pd
import numpy as np
import warnings
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import requests
import yfinance as yf
from scipy import stats
from statsmodels.tsa.stattools import adfuller
from statsmodels.stats.diagnostic import het_breuschpagan
from statsmodels.tsa.arch import arch_model
from pandas.tseries.offsets import BDay
import json
from datetime import datetime, timedelta

warnings.filterwarnings("ignore")

# Configure page
st.set_page_config(
    page_title="Quantitative Event Study Analysis",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for professional styling
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 2rem;
}
.sub-header {
    font-size: 1.5rem;
    color: #2c3e50;
    margin-bottom: 1rem;
}
.metric-card {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 0.5rem;
    border-left: 4px solid #1f77b4;
}
.stAlert {
    margin-top: 1rem;
}
</style>
""", unsafe_allow_html=True)


class EventStudyConfig:
    """Professional configuration class for event study parameters"""

    def __init__(self):
        # Event Definition
        self.event_date = pd.Timestamp("2025-06-02")
        self.event_name = "China Trade Policy Announcement"

        # Analysis Windows
        self.estimation_window = 120
        self.pre_event_window = 3
        self.post_event_window = 3

        # Assets Under Analysis
        self.assets = {
            "MP Materials Corp": "MP",
            "Alibaba Group": "BABA",
            "iShares Semiconductor ETF": "SOXX",
            "VanEck Vectors Semiconductor ETF": "SMH",
            "SPDR S&P 500 ETF": "SPY"
        }

        # Market Data Configuration
        self.risk_free_ticker = "^IRX"
        self.alpha_api_key = "demo"
        self.intervals = ["60min", "30min", "15min"]

        # Statistical Parameters
        self.confidence_level = 0.95
        self.significance_level = 0.05

    def get_date_range(self):
        """Calculate optimal date range for analysis"""
        start = (self.event_date - BDay(self.estimation_window + self.pre_event_window + 10))
        end = (self.event_date + BDay(self.post_event_window + 10))
        return start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d")


class MarketDataProvider:
    """Professional market data provider with multiple sources"""

    def __init__(self, config):
        self.config = config

    def fetch_daily_data(self, ticker):
        """Fetch daily market data with fallback sources"""
        try:
            # Primary source: yfinance (more reliable than Alpha Vantage demo)
            start_date, end_date = self.config.get_date_range()

            stock = yf.Ticker(ticker)
            data = stock.history(start=start_date, end=end_date)

            if data.empty:
                st.warning(f"No data found for {ticker}")
                return None

            # Add technical indicators
            data = self.calculate_market_microstructure_metrics(data)

            return data

        except Exception as e:
            st.error(f"Error fetching data for {ticker}: {str(e)}")
            return None

    def calculate_market_microstructure_metrics(self, data):
        """Calculate advanced market microstructure metrics"""
        if data.empty:
            return data

        try:
            # High-Low spread as proxy for bid-ask spread
            data['HL_Spread'] = (data['High'] - data['Low']) / data['Close']

            # Volume analysis
            data['VolumeMA'] = data['Volume'].rolling(window=20).mean()
            data['VolumeRatio'] = data['Volume'] / data['VolumeMA']

            # Price volatility
            data['Returns'] = data['Close'].pct_change()
            data['RealizedVolatility'] = data['Returns'].rolling(window=20).std() * np.sqrt(252)

            # Technical indicators
            data['RSI'] = self._calculate_rsi(data['Close'])
            data['MACD'], data['MACD_Signal'] = self._calculate_macd(data['Close'])

            # Market impact measures
            data['PriceImpact'] = abs(data['Returns']) / (data['Volume'] / 1e6)
            data['PriceImpact'] = data['PriceImpact'].replace([np.inf, -np.inf], np.nan)

        except Exception as e:
            st.warning(f"Error calculating microstructure metrics: {str(e)}")

        return data

    def _calculate_rsi(self, prices, window=14):
        """Calculate RSI indicator"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def _calculate_macd(self, prices, fast=12, slow=26, signal=9):
        """Calculate MACD indicator"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal


class EventStudyAnalyzer:
    """Professional-grade event study statistical analysis"""

    def __init__(self, config):
        self.config = config
        self.results = {}

    def prepare_returns_data(self, data_dict, rf_data):
        """Prepare and align return series with risk-free rate"""
        returns = {}

        # Handle risk-free rate data
        if rf_data is not None and not rf_data.empty:
            rf_series = (rf_data['RiskFree'] / 100 / 252).fillna(method='ffill')
        else:
            # Create dummy risk-free rate if not available
            rf_series = pd.Series(0.02 / 252, index=pd.date_range(start='2020-01-01', end='2030-12-31', freq='D'))

        for name, df in data_dict.items():
            if df is None or df.empty:
                continue

            # Calculate returns
            df_returns = pd.DataFrame(index=df.index)
            df_returns['Return'] = df['Close'].pct_change()
            df_returns['Volume'] = df['Volume']
            df_returns = df_returns.dropna()

            # Align risk-free rate
            rf_aligned = rf_series.reindex(df_returns.index, method='ffill').fillna(0.02 / 252)
            df_returns['RiskFree'] = rf_aligned
            df_returns['ExcessReturn'] = df_returns['Return'] - df_returns['RiskFree']

            returns[name] = df_returns

        return returns

    def define_analysis_windows(self, returns_df):
        """Define estimation and event windows with precision"""
        try:
            event_idx = returns_df.index.get_indexer([self.config.event_date], method='nearest')[0]
        except:
            # If exact date not found, use closest business day
            business_days = pd.bdate_range(start=returns_df.index[0], end=returns_df.index[-1])
            if len(business_days) > 0:
                closest_date = business_days[business_days.get_indexer([self.config.event_date], method='nearest')[0]]
                event_idx = returns_df.index.get_indexer([closest_date], method='nearest')[0]
            else:
                event_idx = len(returns_df) // 2

        # Define windows with bounds checking
        est_start = max(0, event_idx - self.config.estimation_window - self.config.pre_event_window)
        est_end = max(est_start + 30, event_idx - self.config.pre_event_window)
        event_start = event_idx - self.config.pre_event_window
        event_end = min(len(returns_df) - 1, event_idx + self.config.post_event_window)

        estimation_window = returns_df.iloc[est_start:est_end]
        event_window = returns_df.iloc[event_start:event_end + 1]

        return estimation_window, event_window

    def enhanced_capm_analysis(self, estimation_df, market_returns):
        """Enhanced CAPM with diagnostics and robustness checks"""
        if market_returns is None or estimation_df.empty or market_returns.empty:
            return None, None, {}

        # Align data
        aligned_data = pd.concat([
            estimation_df['ExcessReturn'],
            market_returns['ExcessReturn']
        ], axis=1, join='inner')
        aligned_data.columns = ['Asset', 'Market']
        aligned_data.dropna(inplace=True)

        if len(aligned_data) < 30:
            return None, None, {}

        # Main regression
        y = aligned_data['Asset'].values
        x = aligned_data['Market'].values

        # Handle edge cases
        if np.std(x) == 0 or np.std(y) == 0:
            return None, None, {}

        # Calculate beta and alpha
        try:
            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
        except:
            return None, None, {}

        # Enhanced diagnostics
        residuals = y - (intercept + slope * x)
        diagnostics = {
            'alpha': intercept,
            'beta': slope,
            'r_squared': r_value ** 2,
            'p_value': p_value,
            'std_error_beta': std_err,
            'observations': len(aligned_data),
            'residual_std': np.std(residuals),
            'durbin_watson': self._durbin_watson_test(residuals),
            'jarque_bera_pvalue': stats.jarque_bera(residuals)[1] if len(residuals) > 3 else np.nan,
            'adf_pvalue': adfuller(residuals)[1] if len(residuals) > 12 else np.nan
        }

        return intercept, slope, diagnostics

    def _durbin_watson_test(self, residuals):
        """Calculate Durbin-Watson statistic for autocorrelation"""
        if len(residuals) < 2:
            return np.nan
        diff_residuals = np.diff(residuals)
        return np.sum(diff_residuals ** 2) / np.sum(residuals ** 2)

    def calculate_abnormal_returns(self, event_df, alpha, beta, market_returns):
        """Calculate abnormal returns with statistical significance tests"""
        if market_returns is None or event_df.empty or market_returns.empty:
            return None, {}

        # Align event window data
        aligned_data = pd.concat([
            event_df['ExcessReturn'],
            market_returns['ExcessReturn']
        ], axis=1, join='inner')
        aligned_data.columns = ['Asset', 'Market']
        aligned_data.dropna(inplace=True)

        if aligned_data.empty:
            return None, {}

        # Calculate expected and abnormal returns
        aligned_data['ExpectedReturn'] = alpha + beta * aligned_data['Market']
        aligned_data['AbnormalReturn'] = aligned_data['Asset'] - aligned_data['ExpectedReturn']
        aligned_data['CumulativeAR'] = aligned_data['AbnormalReturn'].cumsum()

        # Statistical tests
        ar_values = aligned_data['AbnormalReturn'].values

        # Basic statistics
        mean_ar = np.mean(ar_values)
        std_ar = np.std(ar_values, ddof=1)
        t_stat = mean_ar / (std_ar / np.sqrt(len(ar_values))) if std_ar > 0 else 0
        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), len(ar_values) - 1))

        # CAR statistics
        car_total = aligned_data['CumulativeAR'].iloc[-1]
        car_variance = len(ar_values) * (std_ar ** 2)
        car_t_stat = car_total / np.sqrt(car_variance) if car_variance > 0 else 0
        car_p_value = 2 * (1 - stats.t.cdf(abs(car_t_stat), len(ar_values) - 1))

        ar_statistics = {
            'mean_ar': mean_ar,
            'std_ar': std_ar,
            't_statistic': t_stat,
            'p_value': p_value,
            'car_total': car_total,
            'car_t_statistic': car_t_stat,
            'car_p_value': car_p_value,
            'observations': len(ar_values)
        }

        return aligned_data, ar_statistics


class VisualizationEngine:
    """Professional visualization engine for event study results"""

    def __init__(self, config):
        self.config = config

    def create_abnormal_returns_chart(self, abnormal_data, asset_name):
        """Create interactive abnormal returns chart"""
        fig = go.Figure()

        # Add abnormal returns bar chart
        fig.add_trace(go.Bar(
            x=abnormal_data.index,
            y=abnormal_data['AbnormalReturn'],
            name='Abnormal Returns',
            marker_color=['red' if x < 0 else 'green' for x in abnormal_data['AbnormalReturn']],
            opacity=0.7
        ))

        # Add zero line
        fig.add_hline(y=0, line_dash="dash", line_color="black", opacity=0.5)

        # Add event date marker
        if self.config.event_date in abnormal_data.index:
            fig.add_vline(x=self.config.event_date, line_dash="dot", line_color="red",
                          annotation_text="Event Date", annotation_position="top")

        fig.update_layout(
            title=f'Abnormal Returns - {asset_name}',
            xaxis_title='Date',
            yaxis_title='Abnormal Return',
            hovermode='x unified',
            height=500
        )

        return fig

    def create_car_evolution_chart(self, abnormal_data, asset_name):
        """Create cumulative abnormal returns evolution chart"""
        fig = go.Figure()

        # Add CAR line
        fig.add_trace(go.Scatter(
            x=abnormal_data.index,
            y=abnormal_data['CumulativeAR'],
            mode='lines+markers',
            name='Cumulative Abnormal Returns',
            line=dict(color='blue', width=3),
            marker=dict(size=6)
        ))

        # Add confidence bands (¬±2 standard deviations)
        std_car = abnormal_data['AbnormalReturn'].std()
        upper_bound = 2 * std_car * np.sqrt(range(1, len(abnormal_data) + 1))
        lower_bound = -2 * std_car * np.sqrt(range(1, len(abnormal_data) + 1))

        fig.add_trace(go.Scatter(
            x=list(abnormal_data.index) + list(abnormal_data.index[::-1]),
            y=list(upper_bound) + list(lower_bound[::-1]),
            fill='tonexty',
            fillcolor='rgba(0,100,80,0.2)',
            line=dict(color='rgba(255,255,255,0)'),
            name='95% Confidence Band',
            showlegend=True
        ))

        # Add zero line
        fig.add_hline(y=0, line_dash="dash", line_color="black", opacity=0.5)

        # Add event date marker
        if self.config.event_date in abnormal_data.index:
            fig.add_vline(x=self.config.event_date, line_dash="dot", line_color="red",
                          annotation_text="Event Date", annotation_position="top")

        fig.update_layout(
            title=f'Cumulative Abnormal Returns (CAR) - {asset_name}',
            xaxis_title='Date',
            yaxis_title='Cumulative Abnormal Return',
            hovermode='x unified',
            height=500
        )

        return fig

    def create_cross_asset_comparison(self, analysis_results):
        """Create cross-asset CAR comparison chart"""
        fig = go.Figure()

        for asset_name, result in analysis_results.items():
            if result['abnormal_returns'] is not None:
                abnormal_data = result['abnormal_returns']
                fig.add_trace(go.Scatter(
                    x=abnormal_data.index,
                    y=abnormal_data['CumulativeAR'],
                    mode='lines+markers',
                    name=asset_name,
                    line=dict(width=2),
                    marker=dict(size=4)
                ))

        # Add zero line
        fig.add_hline(y=0, line_dash="dash", line_color="black", opacity=0.5)

        # Add event date marker
        fig.add_vline(x=self.config.event_date, line_dash="dot", line_color="red",
                      annotation_text="Event Date", annotation_position="top")

        fig.update_layout(
            title='Cross-Asset CAR Comparison',
            xaxis_title='Date',
            yaxis_title='Cumulative Abnormal Return',
            hovermode='x unified',
            height=600,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )

        return fig

    def create_volume_profile_chart(self, market_data, asset_name):
        """Create volume profile and microstructure chart"""
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('Volume Profile', 'High-Low Spread'),
            vertical_spacing=0.1
        )

        # Volume profile
        fig.add_trace(go.Bar(
            x=market_data.index,
            y=market_data['Volume'],
            name='Volume',
            marker_color='lightblue',
            opacity=0.7
        ), row=1, col=1)

        # Volume ratio
        if 'VolumeRatio' in market_data.columns:
            fig.add_trace(go.Scatter(
                x=market_data.index,
                y=market_data['VolumeRatio'],
                mode='lines',
                name='Volume Ratio',
                yaxis='y2',
                line=dict(color='orange', width=2)
            ), row=1, col=1)

        # High-Low spread
        if 'HL_Spread' in market_data.columns:
            fig.add_trace(go.Scatter(
                x=market_data.index,
                y=market_data['HL_Spread'],
                mode='lines+markers',
                name='HL Spread',
                line=dict(color='red', width=2),
                marker=dict(size=4)
            ), row=2, col=1)

        # Add event date marker
        fig.add_vline(x=self.config.event_date, line_dash="dot", line_color="red",
                      annotation_text="Event Date", annotation_position="top")

        fig.update_layout(
            title=f'Market Microstructure Metrics - {asset_name}',
            height=600,
            hovermode='x unified'
        )

        return fig

    def create_technical_indicators_chart(self, market_data, asset_name):
        """Create technical indicators chart"""
        fig = make_subplots(
            rows=3, cols=1,
            subplot_titles=('Price & MACD', 'RSI', 'Realized Volatility'),
            vertical_spacing=0.1
        )

        # Price and MACD
        fig.add_trace(go.Scatter(
            x=market_data.index,
            y=market_data['Close'],
            mode='lines',
            name='Close Price',
            line=dict(color='black', width=2)
        ), row=1, col=1)

        if 'MACD' in market_data.columns:
            fig.add_trace(go.Scatter(
                x=market_data.index,
                y=market_data['MACD'],
                mode='lines',
                name='MACD',
                line=dict(color='blue', width=1),
                yaxis='y2'
            ), row=1, col=1)

        # RSI
        if 'RSI' in market_data.columns:
            fig.add_trace(go.Scatter(
                x=market_data.index,
                y=market_data['RSI'],
                mode='lines',
                name='RSI',
                line=dict(color='purple', width=2)
            ), row=2, col=1)

            # RSI overbought/oversold levels
            fig.add_hline(y=70, line_dash="dash", line_color="red", opacity=0.5, row=2, col=1)
            fig.add_hline(y=30, line_dash="dash", line_color="green", opacity=0.5, row=2, col=1)

        # Realized Volatility
        if 'RealizedVolatility' in market_data.columns:
            fig.add_trace(go.Scatter(
                x=market_data.index,
                y=market_data['RealizedVolatility'],
                mode='lines',
                name='Realized Volatility',
                line=dict(color='orange', width=2)
            ), row=3, col=1)

        # Add event date marker
        fig.add_vline(x=self.config.event_date, line_dash="dot", line_color="red",
                      annotation_text="Event Date", annotation_position="top")

        fig.update_layout(
            title=f'Technical Indicators - {asset_name}',
            height=800,
            hovermode='x unified'
        )

        return fig


class StatisticalTestSuite:
    """Comprehensive statistical testing suite for event studies"""

    def __init__(self, config):
        self.config = config

    def run_comprehensive_tests(self, abnormal_returns):
        """Run comprehensive statistical tests on abnormal returns"""
        results = {}

        # Normality tests
        if len(abnormal_returns) >= 3:
            shapiro_stat, shapiro_p = stats.shapiro(abnormal_returns)
            results['shapiro_statistic'] = shapiro_stat
            results['shapiro_pvalue'] = shapiro_p
        else:
            results['shapiro_statistic'] = np.nan
            results['shapiro_pvalue'] = np.nan

        if len(abnormal_returns) >= 8:
            jb_stat, jb_p = stats.jarque_bera(abnormal_returns)
            results['jarque_bera_statistic'] = jb_stat
            results['jarque_bera_pvalue'] = jb_p
        else:
            results['jarque_bera_statistic'] = np.nan
            results['jarque_bera_pvalue'] = np.nan

        # Location tests
        t_stat, t_p = stats.ttest_1samp(abnormal_returns, 0)
        results['ttest_statistic'] = t_stat
        results['ttest_pvalue'] = t_p

        # Non-parametric tests
        wilcoxon_stat, wilcoxon_p = stats.wilcoxon(abnormal_returns)
        results['wilcoxon_statistic'] = wilcoxon_stat
        results['wilcoxon_pvalue'] = wilcoxon_p

        # Compare with normal distribution
        normal_sample = np.random.normal(0, np.std(abnormal_returns), len(abnormal_returns))
        mw_stat, mw_p = stats.mannwhitneyu(abnormal_returns, normal_sample, alternative='two-sided')
        results['mannwhitney_statistic'] = mw_stat
        results['mannwhitney_pvalue'] = mw_p

        # Kolmogorov-Smirnov test
        ks_stat, ks_p = stats.kstest(abnormal_returns, 'norm',
                                     args=(np.mean(abnormal_returns), np.std(abnormal_returns)))
        results['ks_statistic'] = ks_stat
        results['ks_pvalue'] = ks_p

        # Variance tests
        # Levene test (comparing with theoretical normal)
        levene_stat, levene_p = stats.levene(abnormal_returns, normal_sample)
        results['levene_statistic'] = levene_stat
        results['levene_pvalue'] = levene_p

        return results

    def garch_volatility_analysis(self, returns_series):
        """Perform GARCH volatility modeling"""
        try:
            # Prepare data
            returns_clean = returns_series.dropna() * 100  # Convert to percentage

            if len(returns_clean) < 50:
                return None

            # Fit GARCH(1,1) model
            model = arch_model(returns_clean, vol='Garch', p=1, q=1)
            fitted_model = model.fit(disp='off')

            # Extract volatility
            volatility = fitted_model.conditional_volatility / 100  # Convert back

            results = {
                'model': fitted_model,
                'volatility': volatility,
                'aic': fitted_model.aic,
                'bic': fitted_model.bic,
                'log_likelihood': fitted_model.loglikelihood
            }

            return results

        except Exception as e:
            st.warning(f"GARCH modeling failed: {str(e)}")
            return None


def main():
    # Title and description
    st.markdown('<h1 class="main-header">üè¶ Quantitative Event Study Analysis</h1>', unsafe_allow_html=True)
    st.markdown('<h2 class="sub-header">JP Morgan Data Science Level - Advanced Market Microstructure Analysis</h2>',
                unsafe_allow_html=True)

    st.markdown("""
    **Professional-grade event study implementation featuring:**
    - Multi-timeframe analysis (6H, 1H, 30min intervals)
    - Advanced statistical testing (t-tests, Mann-Whitney U, Kolmogorov-Smirnov)
    - Market microstructure metrics (bid-ask spreads, volume profiles)
    - GARCH volatility modeling
    - Interactive visualizations with statistical confidence intervals
    - Risk-adjusted performance metrics
    """)

    # Initialize session state
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'results_data' not in st.session_state:
        st.session_state.results_data = {}

    # Sidebar configuration
    with st.sidebar:
        st.header("üìä Analysis Configuration")

        # Event configuration
        st.subheader("Event Parameters")
        event_name = st.text_input("Event Name", value="China Trade Policy Announcement")
        event_date = st.date_input("Event Date", value=pd.Timestamp("2025-06-02").date())

        # Window parameters
        st.subheader("Analysis Windows")
        estimation_window = st.slider("Estimation Window (days)", 60, 200, 120)
        pre_event_window = st.slider("Pre-Event Window (days)", 1, 10, 3)
        post_event_window = st.slider("Post-Event Window (days)", 1, 10, 3)

        # Asset selection
        st.subheader("Assets Under Analysis")
        default_assets = {
            "MP Materials Corp": "MP",
            "Alibaba Group": "BABA",
            "iShares Semiconductor ETF": "SOXX",
            "VanEck Vectors Semiconductor ETF": "SMH",
            "SPDR S&P 500 ETF": "SPY"
        }

        selected_assets = {}
        for name, ticker in default_assets.items():
            if st.checkbox(f"{name} ({ticker})", value=True):
                selected_assets[name] = ticker

        # Analysis intervals
        st.subheader("Analysis Intervals")
        intervals = st.multiselect("Select Intervals",
                                   ["60min", "30min", "15min"],
                                   default=["60min", "30min"])

        # Statistical parameters
        st.subheader("Statistical Parameters")
        confidence_level = st.slider("Confidence Level", 0.90, 0.99, 0.95, 0.01)

        # Run analysis button
        run_analysis = st.button("üöÄ Run Event Study Analysis", type="primary")

    # Main content area
    if run_analysis and selected_assets:
        with st.spinner("üîÑ Performing quantitative analysis..."):
            try:
                # Create configuration
                config = EventStudyConfig()
                config.event_date = pd.Timestamp(event_date)
                config.event_name = event_name
                config.estimation_window = estimation_window
                config.pre_event_window = pre_event_window
                config.post_event_window = post_event_window
                config.assets = selected_assets
                config.intervals = intervals
                config.confidence_level = confidence_level

                # Initialize components
                data_provider = MarketDataProvider(config)
                analyzer = EventStudyAnalyzer(config)
                visualizer = VisualizationEngine(config)
                test_suite = StatisticalTestSuite(config)

                # Fetch market data
                st.info("üì° Fetching market data...")
                market_data = {}
                risk_free_data = None

                # Download data for each asset
                for name, ticker in selected_assets.items():
                    data = data_provider.fetch_daily_data(ticker)
                    if data is not None and not data.empty:
                        market_data[name] = data
                        st.success(f"‚úÖ Successfully fetched data for {name} ({ticker})")
                    else:
                        st.warning(f"‚ö†Ô∏è Failed to fetch data for {name} ({ticker})")

                # Fetch risk-free rate
                rf_data = data_provider.fetch_daily_data(config.risk_free_ticker)
                if rf_data is not None and not rf_data.empty:
                    risk_free_data = pd.DataFrame({'RiskFree': rf_data['Close']})
                    st.success("‚úÖ Successfully fetched risk-free rate data")

                if not market_data:
                    st.error("‚ùå No market data available. Please check your asset selection and try again.")
                    return

                # Prepare returns data
                st.info("üî¢ Calculating returns and preparing data...")
                returns_data = analyzer.prepare_returns_data(market_data, risk_free_data)

                # Perform event study analysis
                st.info("üìä Performing event study analysis...")
                analysis_results = {}

                # Get market benchmark (SPY)
                market_returns = returns_data.get("SPDR S&P 500 ETF") or returns_data.get(list(returns_data.keys())[0])

                for asset_name, returns_df in returns_data.items():
                    if asset_name == "SPDR S&P 500 ETF":
                        continue  # Skip market benchmark in individual analysis

                    try:
                        # Define analysis windows
                        estimation_window_data, event_window_data = analyzer.define_analysis_windows(returns_df)

                        # CAPM analysis
                        alpha, beta, diagnostics = analyzer.enhanced_capm_analysis(estimation_window_data,
                                                                                   market_returns)

                        if alpha is not None and beta is not None:
                            # Calculate abnormal returns
                            abnormal_results, ar_stats = analyzer.calculate_abnormal_returns(
                                event_window_data, alpha, beta, market_returns
                            )

                            analysis_results[asset_name] = {
                                'alpha': alpha,
                                'beta': beta,
                                'diagnostics': diagnostics,
                                'abnormal_returns': abnormal_results,
                                'ar_statistics': ar_stats,
                                'estimation_window': estimation_window_data,
                                'event_window': event_window_data
                            }

                            st.success(f"‚úÖ Completed analysis for {asset_name}")
                        else:
                            st.warning(f"‚ö†Ô∏è Insufficient data for CAPM analysis: {asset_name}")

                    except Exception as e:
                        st.error(f"‚ùå Error analyzing {asset_name}: {str(e)}")

                # Store results in session state
                st.session_state.results_data = {
                    'analysis_results': analysis_results,
                    'market_data': market_data,
                    'returns_data': returns_data,
                    'config': config,
                    'market_returns': market_returns
                }
                st.session_state.analysis_complete = True

                st.success("üéâ Event study analysis completed successfully!")

            except Exception as e:
                st.error(f"‚ùå Error during analysis: {str(e)}")
                st.exception(e)

    # Display results if analysis is complete
    if st.session_state.analysis_complete and st.session_state.results_data:
        display_results()


def display_results():
    """Display comprehensive analysis results"""
    results_data = st.session_state.results_data
    analysis_results = results_data['analysis_results']
    config = results_data['config']

    if not analysis_results:
        st.warning("‚ö†Ô∏è No analysis results available. Please run the analysis first.")
        return

    # Create tabs for different views
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Summary Statistics",
        "üìà Abnormal Returns",
        "üìâ Market Microstructure",
        "üî¨ Statistical Tests",
        "üìã Detailed Results"
    ])

    with tab1:
        display_summary_statistics(analysis_results, config)
    with tab2:
        display_abnormal_returns_analysis(analysis_results, config)
    with tab3:
        display_market_microstructure(results_data)
    with tab4:
        display_statistical_tests(analysis_results, config)
    with tab5:
        display_detailed_results(analysis_results, config)


def display_summary_statistics(analysis_results, config):
    """Display summary statistics dashboard"""
    st.markdown('<h2 class="sub-header">üìä Event Study Summary Statistics</h2>', unsafe_allow_html=True)

    # Key metrics overview
    col1, col2, col3, col4 = st.columns(4)
    total_assets = len(analysis_results)
    significant_cars = sum(1 for result in analysis_results.values()
                           if result['ar_statistics']['p_value'] < 0.05)
    avg_car = np.mean([result['ar_statistics']['car_total']
                       for result in analysis_results.values()])
    max_car = max([result['ar_statistics']['car_total']
                   for result in analysis_results.values()])

    with col1:
        st.metric("Assets Analyzed", total_assets)
    with col2:
        st.metric("Significant CARs", f"{significant_cars}/{total_assets}")
    with col3:
        st.metric("Average CAR", f"{avg_car:.4f}")
    with col4:
        st.metric("Maximum CAR", f"{max_car:.4f}")

    # Summary table
    st.subheader("Asset-Level Summary")
    summary_data = []
    for asset_name, result in analysis_results.items():
        summary_data.append({
            'Asset': asset_name,
            'Alpha': f"{result['alpha']:.6f}",
            'Beta': f"{result['beta']:.4f}",
            'R¬≤': f"{result['diagnostics']['r_squared']:.4f}",
            'CAR': f"{result['ar_statistics']['car_total']:.4f}",
            'T-Statistic': f"{result['ar_statistics']['t_statistic']:.4f}",
            'P-Value': f"{result['ar_statistics']['p_value']:.4f}",
            'Significant': "‚úÖ" if result['ar_statistics']['p_value'] < 0.05 else "‚ùå"
        })

    summary_df = pd.DataFrame(summary_data)
    st.dataframe(summary_df, use_container_width=True)


def display_abnormal_returns_analysis(analysis_results, config):
    """Display abnormal returns analysis and visualizations"""
    st.markdown('<h2 class="sub-header">üìà Abnormal Returns Analysis</h2>', unsafe_allow_html=True)

    # Initialize visualization engine
    visualizer = VisualizationEngine(config)

    # Asset selection for detailed view
    asset_names = list(analysis_results.keys())
    selected_asset = st.selectbox("Select Asset for Detailed Analysis", asset_names)

    if selected_asset and selected_asset in analysis_results:
        result = analysis_results[selected_asset]

        # Display key metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Cumulative Abnormal Return",
                      f"{result['ar_statistics']['car_total']:.4f}")
        with col2:
            st.metric("Average Daily AR",
                      f"{result['ar_statistics']['mean_ar']:.4f}")
        with col3:
            st.metric("Statistical Significance",
                      "Significant" if result['ar_statistics']['p_value'] < 0.05 else "Not Significant")

        # Abnormal returns chart
        if result['abnormal_returns'] is not None:
            fig = visualizer.create_abnormal_returns_chart(
                result['abnormal_returns'],
                selected_asset
            )
            st.plotly_chart(fig, use_container_width=True)

        # CAR evolution chart
        if result['abnormal_returns'] is not None:
            fig_car = visualizer.create_car_evolution_chart(
                result['abnormal_returns'],
                selected_asset
            )
            st.plotly_chart(fig_car, use_container_width=True)

    # Cross-asset comparison
    st.subheader("Cross-Asset CAR Comparison")
    fig_comparison = visualizer.create_cross_asset_comparison(analysis_results)
    st.plotly_chart(fig_comparison, use_container_width=True)


def display_market_microstructure(results_data):
    """Display market microstructure analysis"""
    st.markdown('<h2 class="sub-header">üìâ Market Microstructure Analysis</h2>', unsafe_allow_html=True)

    market_data = results_data['market_data']
    config = results_data['config']

    # Initialize visualization engine
    visualizer = VisualizationEngine(config)

    # Asset selection
    asset_names = list(market_data.keys())
    selected_asset = st.selectbox("Select Asset for Microstructure Analysis",
                                  asset_names, key="microstructure_asset")

    if selected_asset and selected_asset in market_data:
        asset_data = market_data[selected_asset].copy()

        # Display metrics around event date
        event_window_start = config.event_date - pd.Timedelta(days=5)
        event_window_end = config.event_date + pd.Timedelta(days=5)
        event_data = asset_data.loc[event_window_start:event_window_end]

        if not event_data.empty:
            # Key microstructure metrics
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                if 'HL_Spread' in event_data.columns:
                    avg_spread = event_data['HL_Spread'].mean()
                    st.metric("Avg HL Spread", f"{avg_spread:.4f}")

            with col2:
                if 'VolumeRatio' in event_data.columns:
                    avg_volume_ratio = event_data['VolumeRatio'].mean()
                    st.metric("Avg Volume Ratio", f"{avg_volume_ratio:.2f}")

            with col3:
                if 'RealizedVolatility' in event_data.columns:
                    avg_volatility = event_data['RealizedVolatility'].mean()
                    st.metric("Realized Volatility", f"{avg_volatility:.4f}")

            with col4:
                if 'RSI' in event_data.columns:
                    current_rsi = event_data['RSI'].iloc[-1]
                    st.metric("Current RSI", f"{current_rsi:.2f}")

            # Microstructure charts
            fig_volume = visualizer.create_volume_profile_chart(event_data, selected_asset)
            st.plotly_chart(fig_volume, use_container_width=True)

            # Technical indicators
            fig_tech = visualizer.create_technical_indicators_chart(event_data, selected_asset)
            st.plotly_chart(fig_tech, use_container_width=True)


def display_statistical_tests(analysis_results, config):
    """Display comprehensive statistical test results"""
    st.markdown('<h2 class="sub-header">üî¨ Advanced Statistical Tests</h2>', unsafe_allow_html=True)

    # Initialize statistical test suite
    test_suite = StatisticalTestSuite(config)

    # Run statistical tests for each asset
    for asset_name, result in analysis_results.items():
        if result['abnormal_returns'] is None:
            continue

        st.subheader(f"Statistical Tests - {asset_name}")

        abnormal_returns = result['abnormal_returns']['AbnormalReturn'].values

        # Perform tests
        test_results = test_suite.run_comprehensive_tests(abnormal_returns)

        # Display test results
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Normality Tests**")
            st.write(f"Shapiro-Wilk p-value: {test_results['shapiro_pvalue']:.6f}")
            st.write(f"Jarque-Bera p-value: {test_results['jarque_bera_pvalue']:.6f}")

            st.markdown("**Significance Tests**")
            st.write(f"T-test p-value: {test_results['ttest_pvalue']:.6f}")
            st.write(f"Wilcoxon p-value: {test_results['wilcoxon_pvalue']:.6f}")

        with col2:
            st.markdown("**Distribution Tests**")
            st.write(f"Mann-Whitney U p-value: {test_results['mannwhitney_pvalue']:.6f}")
            st.write(f"Kolmogorov-Smirnov p-value: {test_results['ks_pvalue']:.6f}")

            st.markdown("**Variance Tests**")
            st.write(f"Levene Test p-value: {test_results['levene_pvalue']:.6f}")

        # Interpretation
        significant_tests = sum(1 for p in [
            test_results['ttest_pvalue'],
            test_results['wilcoxon_pvalue'],
            test_results['mannwhitney_pvalue']
        ] if p < 0.05)

        if significant_tests >= 2:
            st.success("‚úÖ Strong evidence of significant abnormal returns")
        elif significant_tests == 1:
            st.warning("‚ö†Ô∏è Moderate evidence of abnormal returns")
        else:
            st.info("‚ÑπÔ∏è Limited evidence of significant abnormal returns")

        st.divider()


def display_detailed_results(analysis_results, config):
    """Display detailed analysis results and diagnostics"""
    st.markdown('<h2 class="sub-header">üìã Detailed Analysis Results</h2>', unsafe_allow_html=True)

    # Asset selection
    asset_names = list(analysis_results.keys())
    selected_asset = st.selectbox("Select Asset for Detailed Results",
                                  asset_names, key="detailed_asset")

    if selected_asset and selected_asset in analysis_results:
        result = analysis_results[selected_asset]

        # CAPM Diagnostics
        st.subheader("CAPM Model Diagnostics")
        diagnostics = result['diagnostics']

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Model Parameters**")
            st.write(f"Alpha (Œ±): {diagnostics['alpha']:.6f}")
            st.write(f"Beta (Œ≤): {diagnostics['beta']:.4f}")
            st.write(f"R-squared: {diagnostics['r_squared']:.4f}")
            st.write(f"Observations: {diagnostics['observations']}")

        with col2:
            st.markdown("**Statistical Tests**")
            st.write(f"Beta p-value: {diagnostics['p_value']:.6f}")
            st.write(f"Beta std error: {diagnostics['std_error_beta']:.6f}")
            st.write(f"Durbin-Watson: {diagnostics['durbin_watson']:.4f}")
            st.write(f"Residual std: {diagnostics['residual_std']:.6f}")

        # Model quality assessment
        st.markdown("**Model Quality Assessment**")
        quality_score = 0
        if diagnostics['r_squared'] > 0.3:
            quality_score += 1
            st.write("‚úÖ Good explanatory power (R¬≤ > 0.3)")
        else:
            st.write("‚ö†Ô∏è Low explanatory power (R¬≤ ‚â§ 0.3)")

        if diagnostics['p_value'] < 0.05:
            quality_score += 1
            st.write("‚úÖ Statistically significant beta")
        else:
            st.write("‚ö†Ô∏è Beta not statistically significant")

        if 1.5 <= diagnostics['durbin_watson'] <= 2.5:
            quality_score += 1
            st.write("‚úÖ No significant autocorrelation")
        else:
            st.write("‚ö†Ô∏è Potential autocorrelation in residuals")

        # Overall assessment
        if quality_score >= 2:
            st.success("üéØ High-quality CAPM model")
        elif quality_score == 1:
            st.warning("‚ö†Ô∏è Moderate-quality CAPM model")
        else:
            st.error("‚ùå Low-quality CAPM model - interpret results with caution")

        # Raw data display
        st.subheader("Abnormal Returns Data")
        if result['abnormal_returns'] is not None:
            st.dataframe(result['abnormal_returns'], use_container_width=True)

        # Download results
        if st.button("üì• Download Analysis Results", key=f"download_{selected_asset}"):
            # Prepare download data
            download_data = {
                'asset': selected_asset,
                'diagnostics': diagnostics,
                'ar_statistics': result['ar_statistics'],
                'abnormal_returns': result['abnormal_returns'].to_dict() if result[
                                                                                'abnormal_returns'] is not None else None
            }

            st.download_button(
                label="Download JSON",
                data=json.dumps(download_data, indent=2, default=str),
                file_name=f"{selected_asset}_event_study_results.json",
                mime="application/json"
            )


if __name__ == "__main__":
    main()